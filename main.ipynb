{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/font_manager.py:279: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from train import *\n",
    "from params import TrainingParams\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "from params import TransferParams\n",
    "from pipeline import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = TrainingParams()\n",
    "# aws\n",
    "# params.train_path='/home/ubuntu/work/data/unlabeled2017/*.jpg'\n",
    "# mbp\n",
    "# params.train_path='/Users/paul/Work/ai/images/val2017/*.jpg'\n",
    "# azure\n",
    "# params.train_path = '/home/paul/src/images/train2017/*.jpg'\n",
    "# tf\n",
    "params.train_path = 'data/train/val/*.tfr'\n",
    "params.style_path='data/mosaic.jpg'\n",
    "params.batch_size = 4\n",
    "params.num_epoch = 1\n",
    "params.learn_rate = 0.0001\n",
    "params.total_train_sample = 400\n",
    "params.style_weight = 5.0\n",
    "params.content_weight = 1.0\n",
    "params.tv_weight=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_remaining(params, batch, epoch):\n",
    "    time_remaining = 0\n",
    "    if params.last_time is None:\n",
    "        params.last_time = time.perf_counter()\n",
    "    else:\n",
    "        total_epoch = params.num_epoch\n",
    "        if params.restore_epoch is not None:\n",
    "            total_epoch += params.restore_epoch + 1\n",
    "        cur_time = time.perf_counter()\n",
    "        elapsed = cur_time - params.last_time\n",
    "        params.last_time = cur_time\n",
    "        batches_per_epoch = (params.total_train_sample/params.batch_size)\n",
    "        batch_remaining = batches_per_epoch*(total_epoch-epoch) - batch\n",
    "        time_remaining = int(batch_remaining*elapsed)\n",
    "    return time_remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_last(data, entry):\n",
    "#     if len(data) > 20:\n",
    "#         data = data[1:]\n",
    "    data.append(entry)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_loss(params, batch, epoch, total_cost, content_cost, style_cost):\n",
    "    params.cost_history = keep_last(params.cost_history, total_cost)\n",
    "    params.style_history = keep_last(params.style_history, style_cost)\n",
    "    params.content_history =keep_last(params.content_history, content_cost)\n",
    "    t = time_remaining(params, batch, epoch)\n",
    "    plt.title(\"Batch %i of epoch %i. Total Loss: %s. ETA %s \" % (batch, epoch, str(total_cost), str(datetime.timedelta(seconds=t))))\n",
    "    plt.plot(params.cost_history, 'r', params.style_history, 'b', params.content_history, 'g')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_loss_simple(params, batch, epoch, total_cost, content_cost, style_cost):\n",
    "    t = time_remaining(params, batch, epoch)\n",
    "    sys.stdout.write(\"\\r\")\n",
    "    sys.stdout.write(\"Batch %i of epoch %i. Total Loss: %s. ETA %s \" % (batch, epoch, str(total_cost), str(datetime.timedelta(seconds=t))))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Target Style...\n",
      "Defining Input Pipeline...\n",
      "Building Model...\n",
      "Defining Losses...\n",
      "Starting...\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from summaries/model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into summaries/model.ckpt.\n",
      "Batch 1100 of epoch 0. Total Loss: 2.09759e+11. ETA -1 day, 23:56:12 INFO:tensorflow:global_step/sec: 4.28687\n",
      "Batch 1200 of epoch 0. Total Loss: 1.77978e+11. ETA -1 day, 23:55:49 INFO:tensorflow:global_step/sec: 4.37719\n",
      "Batch 1300 of epoch 0. Total Loss: 1.75192e+11. ETA -1 day, 23:55:27 INFO:tensorflow:global_step/sec: 4.37707\n",
      "Batch 1400 of epoch 0. Total Loss: 1.50769e+11. ETA -1 day, 23:55:03 INFO:tensorflow:global_step/sec: 4.3774\n",
      "Batch 1500 of epoch 0. Total Loss: 1.56709e+11. ETA -1 day, 23:54:40 INFO:tensorflow:global_step/sec: 4.37734\n",
      "Batch 1600 of epoch 0. Total Loss: 1.63083e+11. ETA -1 day, 23:54:17 INFO:tensorflow:global_step/sec: 4.37666\n",
      "Batch 1700 of epoch 0. Total Loss: 1.48124e+11. ETA -1 day, 23:53:53 INFO:tensorflow:global_step/sec: 4.37521\n",
      "Batch 1800 of epoch 0. Total Loss: 1.20002e+11. ETA -1 day, 23:53:32 INFO:tensorflow:global_step/sec: 4.37667\n",
      "Batch 1900 of epoch 0. Total Loss: 1.87705e+11. ETA -1 day, 23:53:09 INFO:tensorflow:global_step/sec: 4.37777\n",
      "Batch 1977 of epoch 0. Total Loss: 1.07189e+11. ETA -1 day, 23:52:51 "
     ]
    }
   ],
   "source": [
    "params.cost_history = []\n",
    "params.style_history = []\n",
    "params.content_history = []\n",
    "params.last_time = None\n",
    "params.restore_epoch = None\n",
    "train(params, report_fn=report_loss_simple, start_new=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer(path, out_path=None):\n",
    "    # init    \n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    input_image = process_img(path, crop=False).eval()\n",
    "    input_shape = [1] + list(input_image.shape)\n",
    "    \n",
    "    # make the model\n",
    "    input_placeholder = tf.placeholder(dtype=tf.float32, shape=input_shape, name='input_images')\n",
    "    gen = SpriteGenerator(input_placeholder, 'SpriteGenerator')\n",
    "    \n",
    "    # restore\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, 'data/model/style.ckpt')\n",
    "    \n",
    "    # generate and write out\n",
    "    output = sess.run(gen.output, feed_dict={input_placeholder:np.stack([input_image])})\n",
    "    plt.imshow(output[0]/255.)  \n",
    "    \n",
    "    if out_path is not None:\n",
    "        output = tf.image.encode_jpeg(output[0])  \n",
    "        write = tf.write_file(out_path, output)\n",
    "        sess.run(write)\n",
    "        print('Generate Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer('data/test.jpg', 'data/generated.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
